\begin{problem}{1}
\end{problem}
\begin{solution} 
    $300\times {10}^{6} \times 0.5 \times \frac{2}{365^3}$
\end{solution}
\begin{problem}{2}
\end{problem}
\begin{solution}
    Suppose $n$ identical balls are thrown into $m$ boxes. Let $\Omega$ be the
    set of $m$-tuples where each entry is a non-negative integer and the sum of
    the entries is $n$. Then, by a stars and bars argument, we know that
    $|\Omega| = \binom{n+m-1}{m-1}$. Therefore, 
    \[
      \Pr\left[{\text{first box is empty}}\right] = \frac{\binom{n+m-2}{m-2}}{\binom{n+m-1}{m-1}} = \frac{m-1}{n+m-1}.
    \]
\end{solution}
\begin{problem}{3} 
\end{problem}
\begin{solution}
    Let $\Omega$ be the set of tuples where the first entry ist he number of
    defective items and the second is the number of good items. Then,
    $\Pr\left[{(0,10)}\right] = \frac{\binom{90}{10}}{\binom{100}{100}} =
    \frac{90\cdot 89 \cdot \ldots \cdot 81}{100 \cdot 99 \cdot \ldots \cdot
    91}$.
\end{solution}
\begin{problem}{4}
\end{problem}
\begin{solution}
    By way of contradiction, suppose that $\Pr\left[{|\xi| > C}\right] > 0$ for
    $C > 0$. Then, it follows that there exists some $A' \geq 1$ such that
    $\Pr\left[{|\xi| \geq A'C}\right]> 0$. So, 
    \begin{align*}
        \Exp{|\xi|^m} &= \sum_{\omega \in \Omega} |\xi(\omega)|^m, \\
        &\geq \sum_{\omega \in \set{|\xi| \geq A'C}} |\xi(\omega)|^m, \\
        &\geq A'^mC^m\Pr\left[{|\xi| \geq A'C}\right].
    \end{align*}
    Since $\Pr\left[{|\xi| \geq A'C}\right]$ is constant, clearly there does not
    exist $A > 0$ such that $A \geq A'^m$ for all $m$, thus a contradiction.
\end{solution}
\begin{problem}{5}
\end{problem}
\begin{solution}
    This is the famous hat-check problem. We find the probability that no one
    gets the right letter. Let $\Omega = S_n$, the permutation group of $n$
    elements, also let $C_i$ be the set of all permutations where the
    $i$\textsuperscript{th} element is in the $i$\textsuperscript{th} position.
    Formally, $\sigma \in C_i$ if and only if $\sigma(i) = i$. Then, by the
    inclusion-exclusion principle, we have that 
    \begin{gather*}
        \Pr\left[{\set{\sigma: \exists i, \sigma(i) = i}}\right] = \Pr\left[{\bigcup_{i=1}^n C_i}\right], \\
        = \sum_{i=1}^n \Pr\left[{C_i}\right] - \sum_{i < j} \Pr\left[{C_i \cap C_j}\right] + \sum_{i < j < k} \Pr\left[{C_i \cap C_j \cap C_k}\right] - \ldots.
    \end{gather*}
    Now, we derive the expression for each term in the previous sum. For any
    $\sigma \in C_{i_1} \cap C_{i_2} \cap \ldots \cap C_{i_k}$, $\sigma(i_1) =
    i_1$, $\sigma(i_2) = i_2$, $\ldots$, $\sigma(i_k) = i_k$. Thus,
    $\Pr\left[{C_{i_1} \cap C_{i_2} \cap \ldots \cap C_{i_k}}\right] =
    \frac{(n-k)!}{n!}$. Therefore, $\sum_{i_1 < i_2 < \ldots < i_k}
    \Pr\left[{C_{i_1} \cap C_{i_2} \cap \ldots \cap C_{i_k}}\right] =
    \binom{n}{k}\frac{(n-k)!}{n!} = \frac{1}{k!}$. So,
    \begin{align*}
        \Pr\left[{\set{\sigma: \exists i, \sigma(i) = i}}\right] &= 1 - \frac{1}{2!} + \frac{1}{3!} - \ldots + \frac{(-1)^{n+1}}{n!}, \\
        \lim_{n\to\infty} \Pr\left[{\set{\sigma: \exists i, \sigma(i) = i}}\right] &= 1 - \frac{1}{e}.
    \end{align*}
\end{solution}
\begin{problem}{6}
\end{problem}
\begin{solution}
    The first part of the question is a direct application of a stars and bars
    argument. Then, there are $\binom{n+r-1}{r-1}$ solutions to the equation
    $x_1 + \ldots + x_r = n$. By the same argument, we find that 
    \[
        \Pr\left[{x_1 = a}\right] = \binom{n-a+r-2}{r-2} / \binom{n+r-1}{r-1} =  \frac{(r-1)n!(n-a+r-2)!}{(n+r-1)!(n-a)!}.
    \]
    Now, we take the limit as $r,n\to\infty$ and $n/r \to \rho > 0$. 
    \begin{align*}
        \lim_{\substack{n,r\to\infty\\ n/r\to\rho}}  \frac{(r-1)n!(n-a+r-2)!}{(n+r-1)!(n-a)!} &= \lim_{\substack{n,r\to\infty\\ n/r\to\rho}} \frac{(r-1)n(n-1)\cdots (n-a+1)}{(n+r-1)(n+r-2)\cdots (n-a+r-1)}, \\
        &\approx  \lim_{\substack{n,r\to\infty\\ n/r\to\rho}} \frac{rn^a}{(n+r)^{a+1}}, \\
        &= \frac{r(\rho r)^a}{(\rho r + r)^{a+1}}, \\
        &= \frac{\rho^a}{(\rho + 1)^a}.
    \end{align*}
\end{solution}
\begin{problem}{7}
\end{problem}
\begin{solution}
    Recall, that the Poisson distribution is the measure on $\Z^+$ such that for
    any elementary outcome $k$, $\Pr\left[{k}\right] =
    \frac{\lambda^k}{e^\lambda k!}$. Let $\xi = \Id_{\Z^+}$. Then, 
    \begin{align*}
        \Exp{\xi} &= \sum_{n=0}^\infty \xi(n)\Pr[{n}], \\
        &= \sum_{n=1}^\infty \frac{\lambda^n}{e^\lambda (n-1)!}, \\
        \intertext{expanding the sum to see the Taylor expansion more clearly, we see that}
        &= \frac{\lambda}{e^\lambda}\left(1 + \lambda + \frac{\lambda^2}{2!} + \ldots \right), \\
        &= \frac{\lambda}{e^\lambda}e^\lambda, \tag{by Taylor expansion} \\
        &= \lambda.
    \end{align*}
    Now, we find the variance using the formula $\Var[\xi] = \Exp{\xi^2} - (\Exp{\xi})^2$. So,
    \begin{align*}
        \Exp{\xi^2} &= \sum_{n=0}^\infty \xi(n)^2\Pr[n], \\
        &= e^{-\lambda}\sum_{n=1}^\infty \frac{\lambda^n n}{(n-1)!}, \\
        &= \lambda e^{-\lambda} \sum_{n=0}^\infty \frac{\lambda^n (n+1)}{n!}, \\
        &= \lambda e^{-\lambda} \sum_{n=0}^\infty \frac{\lambda^n}{n!} + \sum_{n=1}^\infty \frac{\lambda^n}{(n-1)!}, \\
        &= \lambda e^{-\lambda} \left(e^\lambda + \lambda \sum_{n=0}^\infty \frac{\lambda^n}{n!}\right), \\
        &= \lambda e^{-\lambda} \left(e^\lambda + \lambda e^\lambda\right), \\
        &= \lambda^2 + \lambda.
    \end{align*}
    Therefore, $\Var[\xi] = \Exp{\xi^2} - (\Exp{\xi})^2 = (\lambda^2 + \lambda) - \lambda^2 = \lambda$ and the variance of the Poisson distribution is the same as its expected value.
\end{solution}
\begin{problem}{9}
\end{problem}
\begin{solution}
    Recall that if $F$ is a distribution function of a random variable $\xi$
    then, $F_\xi(x) = \Pr\left[{\set{\xi(\omega) < x: \omega \in
    \Omega}}\right]$. We then evaluate the expression on the right-hand side
    first 
    \begin{align*}
        \Pr\left[{\set{\omega \in \Omega: \xi(\omega) \leq x}}\right] - \lim_{\delta \downarrow 0} \Pr\left[{\set{\omega \in \Omega: \xi(\omega) \leq x-\delta}}\right] &= \Pr\left[{\set{\omega \in \Omega: \xi(\omega) \leq x}}\right] - \Pr\left[{\bigcup_{i=1}^\infty \set{\omega \in \Omega: \xi(\omega) \leq x - \delta_i}}\right],
    \end{align*}
    where $\delta_1, \delta_2, \ldots$ is any sequence where $\delta_i \geq 0$
    and converges to 0. We first show that \[\bigcup_{i=1}^\infty \set{\omega
    \in \Omega: \xi(\omega) \leq x - \delta_i} = \set{\omega \in \Omega:
    \xi(\omega) < x},\] That the left-hand side is a subset of the right-hand
    side is trivial. Now, suppose an element $\omega$ in the set on the
    right-hand side. There must exist some $\epsilon > 0$, such that
    $\xi(\omega) = x - \epsilon$. By convergence of $\delta_1,\delta_2,\ldots$,
    there must exist some $\delta_i$ where $\xi(\omega) = x - \epsilon \leq x -
    \delta_i$. Thus, the two sets are equivalent. Therefore, 
    \begin{align*}
        \Pr\left[{\set{\omega \in \Omega: \xi(\omega) \leq x}}\right] - \Pr\left[{\bigcup_{i=1}^\infty \set{\omega \in \Omega: \xi(\omega) \leq x - \delta_i}}\right] &= \Pr\left[{\set{\omega \in \Omega: \xi(\omega) \leq x}}\right] - \Pr\left[{\set{\omega \in \Omega: \xi(\omega) < x}}\right], \\
        &= \Pr\left[{\set{\omega \in \Omega: \xi(\omega) = x}}\right], \\
        &= \Pr\left[{\xi = x}\right].
    \end{align*}
    The second equality follows $\sigma$-additivity of $\mathbb{P}$.
\end{solution}
\begin{problem}{10}
\end{problem}
\begin{solution}
    Let $F$ be the distribution of $\xi$ and let $\eta = a\xi + b$ where $a\neq
    0$. We first find the distribution of $\eta$:
    \begin{align*}
        \Pr\left[{\set{\omega \in \Omega: \eta(\omega) \leq x}}\right] &= \Pr\left[{\set{\omega \in \Omega: a\xi(\omega) + b \leq x}}\right], \\
        &= \Pr\left[{\set{\omega\in\Omega:\xi(\omega) \leq \frac{x-b}{a}}}\right], \\
        &= F\left(\frac{x-b}{a}\right).
    \end{align*}
    Thus, taking the derivative to yield the density function, we have that
    $p_\eta(x) = \frac{1}{a}p_\xi\left(\frac{x-b}{a}\right)$ where $p_\xi$ is
    the density of $\xi$. 
\end{solution}
\begin{problem}{11}
\end{problem}
\begin{solution}
    To show this we need a few simple measure-theoretic facts:
    \begin{enumerate}
        \item By definition, the density function of a random variable uniformly
        distributed on some set $A\subset \R$ where $\lambda(A) < \infty$ is
        $\frac{1}{\lambda(A)}$.  Moreover, for any measurable-subset $B\subset
        A$, $\Pr_A[B] = \frac{\lambda(B)}{\lambda(A)}$. For brevity, We call
        $\Pr_A$ the Lebesgue probability measure on $A$. 
        \item Let $C\subset D \subset G \subset \R$ (be measurable-subsets of
        $\R$) and $\Pr_D, \Pr_G$ be the Lebesgue probability measures on $D,G$,
        respectively. Then, by definition, $\Pr_D[C] =
        \frac{\lambda(C)}{\lambda(D)}$ and $\Pr_G[D] =
        \frac{\lambda(D)}{\lambda(G)}$. It follows that $\Pr_G[C] =
        \frac{\lambda(C)}{\lambda(G)} = \Pr_D[C]\Pr_G[D]$.
    \end{enumerate}
    Let $(\Omega_1, \cG_1, \Pr_{\Omega_1})$ and $(\Omega_2, \cG_2,
    \Pr_{\Omega_2})$ be the probability subspaces of $[0,2\pi]$ with the
    Lebesgue probability measure, where $\Omega_1 =[0,\pi/2] \cup [3\pi/2,2\pi]$
    and $\Omega_2 = [\pi/2,3\pi/2]$. Also, let $\Pr_{\Omega_1}, \Pr_{\Omega_2}$
    be the Lebesgue probability measures on $\Omega_1,\Omega_2$, respectively.
    Suppose $\xi = \Id_{[0,2\pi]}$, $\xi_1 = \Id_{[0,\pi/2] \cup
    [3\pi/2,2\pi]}$, $\xi_2 = \Id_{[\pi/2,3\pi/2]}$, and $\eta = \sin(\xi)$.
    Then, we start by finding the distribution of $\eta$:
    \begin{align*}
        \Pr\left[\set{\omega \in [0,2\pi]: \eta(\omega) \leq x}\right] &= \Pr\left[\set{\omega \in [0,\pi/2]\cup [3\pi/2,2\pi]: \eta(\xi(\omega)) \leq x}\right] \\
        &\qquad\qquad\qquad + \Pr\left[\set{\omega \in [\pi/2,3\pi/2]: \eta(\xi(\omega)) \leq x}\right], \\
        &= \frac{1}{2}\Pr_{\Omega_1}\left[\set{\omega \in \Omega_1: \eta(\xi_1(\omega)) \leq x}\right] + \frac{1}{2}\Pr_{\Omega_2}\left[\set{\omega \in \Omega_2: \eta(\xi_2(\omega)) \leq x}\right], \\
        &= \frac{1}{2}F_1(\arcsin(x)) + \frac{1}{2}F_2(\arcsin(x)),
    \end{align*}
    where $F_1,F_2$ are the distribution functions for $\xi_1,\xi_2$, respectively. Differentiating with respect to $x$, we yield the density function:
    \begin{align*}
        \frac{1}{2}\left(F_1(\arcsin(x)) + F_2(\arcsin(x))\right)' &= \frac{1}{2\sqrt{1-x^2}}\left(F_1'(\arcsin x) + F_2'(\arcsin x)\right), \\
        &= \frac{1}{2\sqrt{1-x^2}}\left(\frac{1}{\pi} + \frac{1}{\pi}\right),\\
        &= \frac{1}{\pi\sqrt{1-x^2}}.
    \end{align*}
\end{solution}
\begin{problem}{12}
\end{problem}
\begin{solution}
    Let $\cB(X)$ be the Borel sets of $X$, the $\sigma$-algebra of all of the open sets in $X$. Also let $\cB(X_1) \times \ldots \times \cB(X_n)$ be the product $\sigma$-algebra of $X_1,\ldots,X_n$. That $\cB(X_1) \times \ldots \times \cB(X_n) \subset \cB(X)$ is trivial since the product of open sets in $X_1, \ldots, X_n$ must be an open set in $X$. It remains to show inclusion in the other direction. Since $X$ is a separable metric space, it is second-countable. Moroever, we know that $B = \{x_1 \times \ldots \times x_n : x_1 \in X_1,\ldots,x_n \in X_n\}$ forms a basis of the product topology. Thus, any open set in $X$ can be constructed through the countable unions of sets in $B$. And so, since $\sigma$-algebras are closed under countable unions the inclusion holds in the other direction.
\end{solution}
\begin{problem}{13}
\end{problem}
\begin{solution}
    For any $n > 5$, $n^4 \geq 1000$. Therefore, we are mostly concerned with the set of all perfect squares and cubes less than or equal to 1000. Thus, we find these first using the inclusion-exclusion principle. Then, brute-force count the remaining numbers that do not fall into these sets. 
    \begin{align*}
        \sharp\set{1 \leq n \leq 1000: n^2 \leq 1000~\text{or}~n^3 \leq 1000} &= \sharp \set{1 \leq n \leq 1000: n^2 \leq 1000} + \sharp \set{1 \leq n \leq 1000: n^3 \leq 1000} \\ &\qquad\qquad - \sharp\set{1 \leq n \leq 1000: n^6 \leq 1000}, \\
        &= \lfloor \sqrt{1000} \rfloor + \lfloor \sqrt[3]{1000} \rfloor - 2, \\
        &= 31 + 10 - 3, \\
        &= 39.
    \end{align*}
    It remains to account for numbers where the exponential by $5,7$ are within 1000. This only holds for $2^5,2^7,3^5$. Therefore, there are 41 numbers less than or equal to 1000 that are integer powers (greater than 1) of another integer. Thus, supposing a uniform distribution, the probability of choosing such an integer is $\frac{41}{1000}$.
\end{solution}
\begin{problem}{14}    
\end{problem}
\begin{solution}
    This is a weaker version of the \href{https://en.wikipedia.org/wiki/Borel-Cantelli_lemma}{Borel-Cantelli lemma}. Consider the Lebesgue probability measure on $[0,1]$. And then consider the events $\left[0,\frac{1}{n}\right]$ for $n = 1,2,\ldots$. It follows that $\sum_{k=1}^\infty \Pr\left[\left[0,\frac{1}{n}\right]\right] \not < \infty$, but we know that the limit superior of the probability of this sequence of events is 0. Such a sequence of events cannot be described by the stronger version of the Borel-Cantelli lemma, however, the preconditions in this problem allow for this ``counter example.''

    First, we show the following lemma:
    \begin{lemma}\label{lemma:set-diff}
        For any indexed collection of sets $C_1,C_2,\ldots,C_n$, \[
            \bigcup_{k=1}^n C_k = C_1 \cup \bigcup_{k=1}^{n-1} C_{k+1} \setminus C_k.  
        \]
    \end{lemma}
    \begin{proof}
        We proceed by way of induction. Suppose that $n=2$, then $C_1 \cup (C_2 \setminus C_1) = C_1 \cup (C_1^c \cap C_2) = (C_1 \cup C_1^c) \cap (C_2 \cup C_1) = C_1 \cup C_2$. Assuming the claim true for all $n < N$, we now prove it for $n=N$:
        \begin{align*}
            C_1 \cup \bigcup_{k=1}^{n-1} (C_{k+1} \setminus C_k) &= \left(C_1 \cup \bigcup_{k=1}^{n-2} (C_{k+1} \setminus C_k)\right)\cup (C_n\setminus C_{n-1}), \\
            &= \left(\bigcup_{k=1}^{n-1} C_k \right) \cup (C_{n-1}^c \cap C_n), \tag{by ind. hyp.}\\
            &= \left(\bigcup_{k=1}^{n-2} C_k\right) \cup \left(C_{n-1} \cup (C_{n-1}^c \cap C_n)\right), \\
            &= \left(\bigcup_{k=1}^{n-2} C_k\right) \cup (C_n \cup C_{n-1}), \\
            &= \bigcup_{k=1}^n C_k.
        \end{align*}
    \end{proof}
    With this, we show the desired result:
    \begin{align*}
        \Pr\left[\bigcap_{n=1}^\infty \bigcup_{k=n}^\infty C_k\right] &= \lim_{n\to\infty} \Pr\left[\bigcup_{k=n}^\infty C_k\right], \\
        &= \lim_{n\to\infty} \Pr\left[C_n \cup \bigcup_{k=n}^\infty C_{k+1} \setminus C_k\right], \\
        &\leq \lim_{n\to\infty} \Pr[C_n] + \lim_{n\to\infty} \sum_{k=n}^\infty \Pr[C_{k+1} \setminus C_k], \\
        &= 0.
    \end{align*}
    The second equality follows from Lemma~\ref{lemma:set-diff} and the last equality follows from the given.
\end{solution}
\begin{problem}{15}
\end{problem}
\begin{solution}
    If $F$ is a continuous distribution of a random variable $\xi$ on the probability space $(\Omega, \cG, \cP)$, then it must be that $F$ is injective on $\img \xi$. Consider, now a random variable $\eta = F(\xi)$. We proceed to find the distribution of this $\eta$:
    \begin{align*}
        \Pr[\set{\omega \in \Omega: \eta(\xi(\omega)) \leq x}] &= \Pr[\set{\omega \in \Omega: \xi(\omega) \leq F^{-1}(x)}], \\
        &= F(F^{-1}(x)).
    \end{align*}
    \color{brickred}{Note that unless $F$ is bijective, $F\circ F^{-1} \neq \Id$. Recall, that there exists a right-inverse if and only if $F$ is surjective.} 
\end{solution}